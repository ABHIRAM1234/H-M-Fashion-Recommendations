{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVpWJzj3cr9H",
        "outputId": "f401795c-5704-4b17-af1d-711f03ca9527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepmatch in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from deepmatch) (2.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from deepmatch) (2.23.0)\n",
            "Requirement already satisfied: deepctr==0.8.2 in /usr/local/lib/python3.7/dist-packages (from deepmatch) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py->deepmatch) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->deepmatch) (1.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepmatch) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepmatch) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepmatch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepmatch) (2021.10.8)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install deepmatch\n",
        "! pip install 'h5py==2.10.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEw9Y3BMiZkY",
        "outputId": "77438a11-f621-498c-9f86-156b01467194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "msE6aftuarhe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TPbDrVdjarhf"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xpImY3Marhf",
        "outputId": "526adde0-007f-48b1-bac5-ba37b84ff971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model, load_model\n",
        "\n",
        "from deepmatch.models import *\n",
        "from deepmatch.utils import sampledsoftmaxloss\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3PIw9xJiwakl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dnkjp8exarhg"
      },
      "outputs": [],
      "source": [
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Data"
      ],
      "metadata": {
        "id": "ffEeCDXqUtgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VCHQ7crVarhh"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "    def __init__(self, data_dir:str):\n",
        "        self.base = data_dir # data diectory\n",
        "    \n",
        "    def _load_raw_data(self) -> dict:\n",
        "        \"\"\"Load original raw data\n",
        "\n",
        "        Returns:\n",
        "            dict: raw data dictionary\n",
        "        \"\"\"\n",
        "        articles  = pd.read_csv(self.base+'articles.csv')\n",
        "        customers = pd.read_csv(self.base+'customers.csv')\n",
        "        trans     = pd.read_csv(self.base+'transactions_train.csv')\n",
        "\n",
        "        return {'item':articles, 'user':customers, 'trans':trans}\n",
        "    \n",
        "    def _encode_id(self, data:dict, map_dir:str) -> dict:\n",
        "        \"\"\"Encode user and item id as integers\n",
        "\n",
        "        Args:\n",
        "            data (dict): raw data dictionary, keys: 'item', 'user', 'trans'\n",
        "            map_dir (str): relative directory to store index-id-maps\n",
        "\n",
        "        Returns:\n",
        "            dict: data dictionary\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(self.base+map_dir):\n",
        "            os.mkdir(self.base+map_dir)\n",
        "\n",
        "        user_id2index_path = self.base + map_dir + 'user_id2index.pkl'\n",
        "        user_index2id_path = self.base + map_dir + 'user_index2id.pkl'\n",
        "        item_id2index_path = self.base + map_dir + 'item_id2index.pkl'\n",
        "        item_index2id_path = self.base + map_dir + 'item_index2id.pkl'\n",
        "\n",
        "        user_id2index_dict = dict(zip(data['user']['customer_id'], data['user'].index+1))\n",
        "        user_index2id_dict = dict(zip(data['user'].index+1, data['user']['customer_id']))\n",
        "        item_id2index_dict = dict(zip(data['item']['article_id'], data['item'].index+1))\n",
        "        item_index2id_dict = dict(zip(data['item'].index+1, data['item']['article_id']))\n",
        "        pickle.dump(user_id2index_dict, open(user_id2index_path, 'wb'))\n",
        "        pickle.dump(user_index2id_dict, open(user_index2id_path, 'wb'))\n",
        "        pickle.dump(item_id2index_dict, open(item_id2index_path, 'wb'))\n",
        "        pickle.dump(item_index2id_dict, open(item_index2id_path, 'wb'))\n",
        "        \n",
        "        data['trans']['customer_id'] = data['trans']['customer_id'].map(user_id2index_dict)\n",
        "        data['trans']['article_id']  = data['trans']['article_id'].map(item_id2index_dict)\n",
        "        data['user']['customer_id']  = data['user']['customer_id'].map(user_id2index_dict)\n",
        "        data['item']['article_id']   = data['item']['article_id'].map(item_id2index_dict)\n",
        "\n",
        "        return data\n",
        "    \n",
        "    def _transform_feats(self, data:dict) -> dict:\n",
        "        \"\"\"Transform features (label encode and change dtypes)\n",
        "\n",
        "        Args:\n",
        "            data (dict): data dictionary, keys: 'item', 'user', 'trans'\n",
        "\n",
        "        Returns:\n",
        "            dict: data dictionary\n",
        "        \"\"\"\n",
        "        trans = data['trans']\n",
        "        user = data['user'].fillna(-1)\n",
        "        item = data['item']\n",
        "\n",
        "        # Transactions\n",
        "        trans['price'] = trans['price'].astype('float32')\n",
        "        trans['sales_channel_id'] = trans['sales_channel_id'].astype('int8')\n",
        "\n",
        "        # Customers\n",
        "        user_sparse_feats = [x for x in user.columns if x not in ['age']]\n",
        "        for feat in tqdm([x for x in user_sparse_feats if x!='customer_id'], 'Encode User Sparse Feats'):\n",
        "            lbe = LabelEncoder()\n",
        "            user[feat] = lbe.fit_transform(user[feat].astype(str)) + 1\n",
        "            user[feat] = user[feat].astype('int32')\n",
        "        \n",
        "        # Articles\n",
        "        item_sparse_feats = ['article_id', 'product_code', 'product_type_no', 'product_group_name', \n",
        "                             'graphical_appearance_no', 'colour_group_code', 'perceived_colour_value_id', \n",
        "                             'perceived_colour_master_id', 'department_no', 'index_code', 'index_group_no', \n",
        "                             'section_no', 'garment_group_no']\n",
        "        for feat in tqdm([x for x in item_sparse_feats if x!='article_id'], 'Encode Item Sparse Feats'):\n",
        "            lbe = LabelEncoder()\n",
        "            item[feat] = lbe.fit_transform(item[feat].astype(str)) + 1\n",
        "            item[feat] = item[feat].astype('int32')\n",
        "        \n",
        "        data['trans'] = trans\n",
        "        data['user'] = user\n",
        "        data['item'] = item[item_sparse_feats]\n",
        "\n",
        "        return data\n",
        "    \n",
        "\n",
        "    def save_data(self, data:dict, name:str):\n",
        "        \"\"\"Save data dictionary as parquet\n",
        "\n",
        "        Args:\n",
        "            data (dict): data dictionary, keys: 'item', 'user', 'trans'\n",
        "            name (str): name of the data dict (data versioning)\n",
        "        \"\"\"\n",
        "        path = self.base+name+'/'\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "        data['user'].to_parquet(path+'user.pqt')\n",
        "        data['item'].to_parquet(path+'item.pqt')\n",
        "        data['trans'].to_parquet(path+'trans.pqt')\n",
        "    \n",
        "    def load_data(self, name:str) -> dict:\n",
        "        \"\"\"Load data dictionary\n",
        "\n",
        "        Args:\n",
        "            name (str): name of data dict\n",
        "\n",
        "        Raises:\n",
        "            OSError: invalid data version\n",
        "\n",
        "        Returns:\n",
        "            dict: loaded data dictionary\n",
        "        \"\"\"\n",
        "        path = self.base+name+'/'\n",
        "        if not os.path.exists(path):\n",
        "            raise OSError\n",
        "        data = {}\n",
        "        data['user'] = pd.read_parquet(path+'user.pqt')\n",
        "        data['item'] = pd.read_parquet(path+'item.pqt')\n",
        "        data['trans'] = pd.read_parquet(path+'trans.pqt')\n",
        "\n",
        "        return data\n",
        "    \n",
        "    def preprocess_data(self, save:bool=True, name:str='encoded_full') -> dict:\n",
        "        \"\"\"Preprocess raw data\n",
        "\n",
        "        Args:\n",
        "            save (bool, optional): whether to save the preprocessed data. Defaults to True.\n",
        "            name (str, optional): version name of the data to be saved\n",
        "\n",
        "        Returns:\n",
        "            dict: preprocessed data\n",
        "        \"\"\"\n",
        "        data = self._load_raw_data()\n",
        "        data = self._encode_id(data, 'index_id_map/')\n",
        "        data = self._transform_feats(data)\n",
        "        if save:\n",
        "            self.save_data(data, name)\n",
        "        return data\n",
        "    \n",
        "\n",
        "    def gen_data_set(self, data_name:str, dataset_name:str, features:List[str], \n",
        "                           data:dict, train_end_date:str, val_end_date:str, seq_max_len:int, negsample:int=0):\n",
        "        \"\"\"Generate train set and valid set\n",
        "\n",
        "        Args:\n",
        "            data_name (str): version name of data dictionary\n",
        "            dataset_name (str): version name of dataset\n",
        "            features (List[str]): feature list\n",
        "            data (dict): data dictionary, keys: 'user', 'item', 'trans'\n",
        "            train_end_date (str): end date of train set\n",
        "            val_end_date (str): end date of valid set\n",
        "            seq_max_len (int): maximum history sequence length\n",
        "            negsample (int, optional): number of negative samples. Defaults to 0.\n",
        "\n",
        "        \"\"\"\n",
        "        args = {\n",
        "            'features':features,\n",
        "            'train_end_date':train_end_date,\n",
        "            'val_end_date':val_end_date,\n",
        "            'seq_max_len':seq_max_len,\n",
        "            'negsample':negsample\n",
        "        }\n",
        "\n",
        "        data['trans'].sort_values(\"t_dat\",inplace=True)\n",
        "        trans = data['trans']\n",
        "        # Split train set and valid set\n",
        "        train_data = trans.loc[trans['t_dat']<=train_end_date]\n",
        "        val_data = trans.loc[(train_end_date<trans['t_dat']) & (trans['t_dat']<=val_end_date)]\n",
        "\n",
        "        item_ids = set(data['item']['article_id'].values)\n",
        "        \n",
        "        # Calculate number of rows of train set and valid set to fasten the dataset generating process\n",
        "        counter = train_data[['customer_id','article_id']].groupby('customer_id',as_index=False).count()\n",
        "        train_rows = (counter['article_id'] * (negsample+1)).sum()\n",
        "\n",
        "        # Generate rows\n",
        "        # train_set format: [custID, articleID, label, history_seq_len, history_seq]\n",
        "        # valid_set format: [custID, history_seq_len, history_seq]\n",
        "        train_set = np.zeros((train_rows, 5), dtype=object)\n",
        "        train_customers = list(train_data['customer_id'].unique())\n",
        "        val_customers = list(val_data['customer_id'].unique())\n",
        "        val_set = np.zeros((len(train_customers), 3), dtype=object)\n",
        "        val_label = val_data.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
        "        val_label['article_id'] = val_label['article_id'].apply(lambda x:' '.join([str(i) for i in x]))\n",
        "\n",
        "        p,q = 0,0\n",
        "        for custID, hist in tqdm(train_data.groupby('customer_id'), 'Generate train set'):\n",
        "            pos_list = hist['article_id'].tolist()\n",
        "            if negsample > 0:\n",
        "                candidate_set = list(item_ids - set(pos_list)) # Negative samples\n",
        "                neg_list = np.random.choice(candidate_set, size=len(pos_list)*negsample, replace=True)\n",
        "            for i in range(len(pos_list)):\n",
        "                hist = pos_list[:i+1]\n",
        "                # Positive sample\n",
        "                train_set[p] = [custID, pos_list[i], 1, len(hist[::-1]), hist[::-1]]\n",
        "                p += 1\n",
        "                #Negative smaples\n",
        "                for negi in range(negsample):\n",
        "                    train_set[p] = [custID, neg_list[i*negsample+negi], 0, len(hist[::-1]), hist[::-1]]\n",
        "                    p += 1\n",
        "            val_set[q] = [custID, len(pos_list), pos_list[::-1]]\n",
        "            q += 1\n",
        "        # val_set = val_set[np.isin(val_set[:,0], val_customers)]\n",
        "\n",
        "        np.random.seed(2022)\n",
        "        np.random.shuffle(train_set)\n",
        "        np.random.shuffle(val_set)\n",
        "\n",
        "        # Generate other features and save\n",
        "        path = self.base + data_name + '/' + dataset_name + '/'\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "        \n",
        "        json.dump(args, open(path+'args.json','w')) # save args\n",
        "        \n",
        "        user = data['user']\n",
        "        item = data['item']\n",
        "        user = user.set_index('customer_id')\n",
        "        item = item.set_index('article_id')\n",
        "\n",
        "        train_uid = train_set[:,0]\n",
        "        train_iid = train_set[:,1]\n",
        "        hist_seq = train_set[:,4].tolist()\n",
        "        hist_seq_pad = pad_sequences(hist_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
        "        np.save(open(path+'train_customer_id.npy','wb'), train_uid)\n",
        "        np.save(open(path+'train_article_id.npy','wb'), train_iid)\n",
        "        np.save(open(path+'train_label.npy','wb'), train_set[:,2])\n",
        "        np.save(open(path+'train_hist_len.npy','wb'), train_set[:,3])\n",
        "        np.save(open(path+'train_hist_article_id.npy','wb'), hist_seq_pad)\n",
        "\n",
        "        val_uid = val_set[:,0]\n",
        "        hist_seq = val_set[:,2].tolist()\n",
        "        hist_seq_pad = pad_sequences(hist_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
        "        np.save(open(path+'valid_customer_id.npy','wb'), val_uid)\n",
        "        np.save(open(path+'valid_hist_len.npy','wb'), val_set[:,1])\n",
        "        np.save(open(path+'valid_hist_article_id.npy','wb'), hist_seq_pad)\n",
        "        val_label.to_csv(path+'valid_label.csv', index=False)\n",
        "\n",
        "        del train_set, val_set, hist_seq, hist_seq_pad\n",
        "        gc.collect()\n",
        "\n",
        "        for key in tqdm([x for x in user.columns if x in features and x!='customer_id']):\n",
        "            train_tmp_array = user[key].loc[train_uid].values\n",
        "            val_tmp_array = user[key].loc[val_uid].values\n",
        "            np.save(open(path+'train_'+key+'.npy','wb'), train_tmp_array)\n",
        "            np.save(open(path+'valid_'+key+'.npy','wb'), val_tmp_array)\n",
        "            del train_tmp_array, val_tmp_array\n",
        "            gc.collect()\n",
        "        \n",
        "        del train_uid, user\n",
        "        gc.collect()\n",
        "        \n",
        "        for key in tqdm([x for x in item.columns if x in features and x!='article_id']):\n",
        "            train_tmp_array = item[key].loc[train_iid].values\n",
        "            np.save(open(path+'train_'+key+'.npy','wb'), train_tmp_array)\n",
        "            del train_tmp_array\n",
        "            gc.collect()\n",
        "    \n",
        "    def load_dataset(self, data_name:str, dataset_name:str, customer_feats:List[str], article_feats:List[str]) -> Tuple:\n",
        "        \"\"\"Load saved dataset\n",
        "\n",
        "        Args:\n",
        "            data_name (str): version name of data used to generate dataset\n",
        "            dataset_name (str): version name of dataset\n",
        "            customer_feats (List[str]): list of customer features to be loaded\n",
        "            article_feats (List[str]): list of article features to be loaded\n",
        "\n",
        "        Returns:\n",
        "            Tuple: [train set, valid set]\n",
        "        \"\"\"\n",
        "        path = self.base + data_name + '/' + dataset_name + '/'\n",
        "        if not os.path.exists(path):\n",
        "            raise OSError\n",
        "\n",
        "        train_set = {}\n",
        "        val_set = {}\n",
        "\n",
        "        for feat in tqdm(customer_feats + ['hist_article_id', 'hist_len'], 'Load Customer Features'):\n",
        "            train_set[feat] = np.load(open(path+'train_'+feat+'.npy','rb'), allow_pickle=True)\n",
        "            val_set[feat] = np.load(open(path+'valid_'+feat+'.npy','rb'), allow_pickle=True)\n",
        "\n",
        "        for feat in tqdm(article_feats, 'Load Article Features'):\n",
        "            train_set[feat] = np.load(open(path+'train_'+feat+'.npy','rb'), allow_pickle=True)\n",
        "\n",
        "        train_label = np.load(open(path+'train_label.npy','rb'), allow_pickle=True)\n",
        "        val_label = pd.read_csv(path+'valid_label.csv')\n",
        "\n",
        "        return train_set, train_label, val_set, val_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ErK7SWhvarhm"
      },
      "outputs": [],
      "source": [
        "dp = DataProcessor('/content/drive/MyDrive/HM-RecSys/data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cyk7DwVDarhn"
      },
      "outputs": [],
      "source": [
        "# data = dp.preprocess_data(save=True) # run in the first run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U-q_73Kxarhn"
      },
      "outputs": [],
      "source": [
        "data = dp.load_data(name='encoded_full')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGB0bIkWarho",
        "outputId": "c7567be0-6d04-4323-8878-ee6c0f3223c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate train set: 100%|██████████| 1356709/1356709 [04:36<00:00, 4914.07it/s]\n",
            "100%|██████████| 6/6 [07:00<00:00, 70.15s/it]\n",
            "100%|██████████| 12/12 [13:29<00:00, 67.48s/it]\n"
          ]
        }
      ],
      "source": [
        "features = list(data['user'].columns) + list(data['item'].columns)\n",
        "args = {\n",
        "    'data_name':'encoded_full', \n",
        "    'dataset_name':'200915',\n",
        "    'features':features,\n",
        "    'data':data,\n",
        "    'train_end_date':'2020-09-15',\n",
        "    'val_end_date':'2020-09-22',\n",
        "    'seq_max_len':20,\n",
        "    'negsample':0\n",
        "}\n",
        "# dp.gen_data_set(**args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'run_name':'baseline',\n",
        "    # data params\n",
        "    'user_sparse_feats':['customer_id','FN','Active','club_member_status','fashion_news_frequency','postal_code'],\n",
        "    'user_dense_feats':['age'],\n",
        "    'item_sparse_feats':['article_id'], # ,'product_code','product_type_no'\n",
        "    'item_dense_feats':[],\n",
        "    # model params\n",
        "    'dynamic_k':False,\n",
        "    'p':1,\n",
        "    'k_max':12,\n",
        "\n",
        "    'embedding_dim':64,\n",
        "    'seq_len':args['seq_max_len'],\n",
        "    'num_sampled':100,\n",
        "    'dnn_hidden_units':(128, 64, 64),\n",
        "    'optimizer':'adam',\n",
        "    # training params\n",
        "    'batch_size':2**15,\n",
        "    'epoch':15,\n",
        "    'verbose':1,\n",
        "    'validation_split':0.0\n",
        "}"
      ],
      "metadata": {
        "id": "vtbFS3RVImuA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "40ly0ht7arho"
      },
      "outputs": [],
      "source": [
        "# train_features = list(data['user'].columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_feats = params['user_sparse_feats'] + params['user_dense_feats']\n",
        "article_feats = params['item_sparse_feats'] + params['item_dense_feats']"
      ],
      "metadata": {
        "id": "EiK8DaiNJROW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mq23GBXarhp",
        "outputId": "4dddc5e4-942a-4394-a53c-fd366dee30b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Load Customer Features: 100%|██████████| 9/9 [00:15<00:00,  1.74s/it]\n",
            "Load Article Features: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n"
          ]
        }
      ],
      "source": [
        "train_set, train_label, val_set, val_label = dp.load_dataset('encoded_full', '200915', customer_feats, article_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0yCWxQxM3se"
      },
      "source": [
        "# Load Data and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zi7PPyHTbLG1"
      },
      "outputs": [],
      "source": [
        "feature_dim = {}\n",
        "for feat in data['user'].columns:\n",
        "    feature_dim[feat] = data['user'][feat].max()+1\n",
        "for feat in data['item'].columns:\n",
        "    feature_dim[feat] = data['item'][feat].max()+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "douo4DUxarhs"
      },
      "outputs": [],
      "source": [
        "user_feature_columns = [SparseFeat(x, feature_dim[x], params['embedding_dim']) for x in params['user_sparse_feats']] +\\\n",
        "                       [DenseFeat(x) for x in params['user_dense_feats']] +\\\n",
        "                       [VarLenSparseFeat(SparseFeat('hist_article_id', feature_dim['article_id'], params['embedding_dim'],\n",
        "                                                    embedding_name=\"article_id\"), params['seq_len'], 'mean', 'hist_len')]\n",
        "item_feature_columns = [SparseFeat(x, feature_dim[x], params['embedding_dim']) for x in params['item_sparse_feats']] +\\\n",
        "                       [DenseFeat(x) for x in params['item_dense_feats']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Define Model and train\n",
        "path = dp.base+args['data_name']+'/'+args['dataset_name']+'/'\n",
        "if not os.path.exists(path+params['run_name']):\n",
        "    os.mkdir(path+params['run_name'])\n",
        "path += params['run_name']+'/'"
      ],
      "metadata": {
        "id": "omQBVrFhcYoB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2J1yiTubLG1",
        "outputId": "3ecfe5a7-2a42-4897-e17d-68f83b435019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f746c9cbf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f746c9cbf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f746c9cbf50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f74c9ca6310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f74c9ca6310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f74c9ca6310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74c9ca63d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74c9ca63d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74c9ca63d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f107e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f107e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f107e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method CapsuleLayer.call of <deepmatch.layers.core.CapsuleLayer object at 0x7f74efa2fdd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method CapsuleLayer.call of <deepmatch.layers.core.CapsuleLayer object at 0x7f74efa2fdd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method CapsuleLayer.call of <deepmatch.layers.core.CapsuleLayer object at 0x7f74efa2fdd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f758484a4d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74be2a4e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74be2a4e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f74be2a4e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f750271a2d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7552f19650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7552f19650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7552f19650>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method DNN.call of <deepctr.layers.core.DNN object at 0x7f7552f00cd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method DNN.call of <deepctr.layers.core.DNN object at 0x7f7552f00cd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method DNN.call of <deepctr.layers.core.DNN object at 0x7f7552f00cd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x7f75848412d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x7f75848412d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x7f75848412d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7584867e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7584867e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x7f7584867e90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f13d310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f13d310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x7f746f13d310>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method LabelAwareAttention.call of <deepmatch.layers.core.LabelAwareAttention object at 0x7f7552f00910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method LabelAwareAttention.call of <deepmatch.layers.core.LabelAwareAttention object at 0x7f7552f00910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method LabelAwareAttention.call of <deepmatch.layers.core.LabelAwareAttention object at 0x7f7552f00910>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x7f74d5e83090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Entity <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x7f74d5e83090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Entity <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x7f74d5e83090>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "Train on 31548013 samples\n",
            "Epoch 1/15\n",
            "31548013/31548013 [==============================] - 228s 7us/sample - loss: 2.3692\n",
            "Epoch 2/15\n",
            "25657344/31548013 [=======================>......] - ETA: 42s - loss: 2.0909"
          ]
        }
      ],
      "source": [
        "K.set_learning_phase(True)\n",
        "json.dump(params, open(path+'model_params.json','w'))\n",
        "# if tf.__version__ >= '2.0.0':\n",
        "#     tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=params['num_sampled'], user_dnn_hidden_units=params['dnn_hidden_units'])\n",
        "model = MIND(user_feature_columns,item_feature_columns, dynamic_k=params['dynamic_k'], \n",
        "             p=params['p'], k_max=params['k_max'], num_sampled=params['num_sampled'], \n",
        "             user_dnn_hidden_units=params['dnn_hidden_units'])\n",
        "params['model_name'] = 'MIND'\n",
        "model.compile(optimizer=params['optimizer'], loss=sampledsoftmaxloss)  # \"binary_crossentropy\")\n",
        "\n",
        "history = model.fit(train_set, train_label,\n",
        "                    batch_size=params['batch_size'], \n",
        "                    epochs=params['epoch'],\n",
        "                    verbose=params['verbose'],\n",
        "                    validation_split=params['validation_split'])\n",
        "model.save(path+params['model_name']+'.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_0RhCC7VdVm"
      },
      "outputs": [],
      "source": [
        "params['model_name'] = 'MIND'\n",
        "model = MIND(user_feature_columns,item_feature_columns, dynamic_k=params['dynamic_k'], \n",
        "             p=params['p'], k_max=params['k_max'], num_sampled=params['num_sampled'], \n",
        "             user_dnn_hidden_units=params['dnn_hidden_units'])\n",
        "# model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=params['num_sampled'], user_dnn_hidden_units=params['dnn_hidden_units'])\n",
        "model.load_weights(path+params['model_name']+'.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVPCJ5UsOQjc"
      },
      "outputs": [],
      "source": [
        "# 4. Generate user features for testing and full item features for retrieval\n",
        "all_item_model_input = {\"article_id\": data['item']['article_id'].values}\n",
        "\n",
        "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
        "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
        "\n",
        "user_embs = user_embedding_model.predict(val_set, batch_size=2 ** 12)\n",
        "# user_embs = user_embs[:, i, :]  # i in [0,k_max) if MIND\n",
        "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
        "\n",
        "print(user_embs.shape)\n",
        "print(item_embs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_G3KWslKmJo"
      },
      "source": [
        "# Use faiss to Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2ZNYNBOOqrN"
      },
      "outputs": [],
      "source": [
        "! pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TY1l27iJU8U"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "# from deepmatch.utils import recall_N\n",
        "\n",
        "# index = faiss.IndexFlatIP(params['embedding_dim'])\n",
        "# faiss.normalize_L2(item_embs)\n",
        "# index.add(item_embs)\n",
        "# faiss.normalize_L2(user_embs)\n",
        "# gpu_res = faiss.StandardGpuResources()\n",
        "# gpu_index_flat = faiss.index_cpu_to_gpu(gpu_res, 0, index)\n",
        "\n",
        "# D, I = gpu_index_flat.search(np.ascontiguousarray(user_embs), 12)\n",
        "# s = []\n",
        "# hit = 0\n",
        "# for i, uid in tqdm(enumerate(val_set['customer_id'])):\n",
        "#     try:\n",
        "#         pred = [data['item']['article_id'].values[x] for x in I[i]]\n",
        "#         filter_item = None\n",
        "#         recall_score = recall_N(test_true_label[uid], pred, N=12)\n",
        "#         s.append(recall_score)\n",
        "#         if test_true_label[uid] in pred:\n",
        "#             hit += 1\n",
        "#     except:\n",
        "#         print(i)\n",
        "# print(\"\")\n",
        "# print(\"recall\", np.mean(s))\n",
        "# print(\"hit rate\", hit / len(test_user_model_input['customer_id']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apk(actual, predicted, k=10):\n",
        "    \"\"\"\n",
        "    Computes the average precision at k.\n",
        "    This function computes the average prescision at k between two lists of\n",
        "    items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of elements that are to be predicted (order doesn't matter)\n",
        "    predicted : list\n",
        "                A list of predicted elements (order does matter)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    if len(predicted)>k:\n",
        "        predicted = predicted[:k]\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i,p in enumerate(predicted):\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "    if not actual:\n",
        "        return 0.0\n",
        "\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "def mapk(actual, predicted, k=12):\n",
        "    \"\"\"\n",
        "    Computes the mean average precision at k.\n",
        "    This function computes the mean average prescision at k between two lists\n",
        "    of lists of items.\n",
        "    Parameters\n",
        "    ----------\n",
        "    actual : list\n",
        "             A list of lists of elements that are to be predicted \n",
        "             (order doesn't matter in the lists)\n",
        "    predicted : list\n",
        "                A list of lists of predicted elements\n",
        "                (order matters in the lists)\n",
        "    k : int, optional\n",
        "        The maximum number of predicted elements\n",
        "    Returns\n",
        "    -------\n",
        "    score : double\n",
        "            The mean average precision at k over the input lists\n",
        "    \"\"\"\n",
        "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted) if a]) # CHANGES: ignore null actual (variable=a)"
      ],
      "metadata": {
        "id": "gwKrJTn_nrcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXKHtVqHbyx8"
      },
      "outputs": [],
      "source": [
        "index = faiss.IndexFlatIP(params['embedding_dim'])\n",
        "index.add(item_embs)\n",
        "gpu_res = faiss.StandardGpuResources()\n",
        "gpu_index_flat = faiss.index_cpu_to_gpu(gpu_res, 0, index)\n",
        "\n",
        "predictions = {}\n",
        "D, I = gpu_index_flat.search(np.ascontiguousarray(user_embs), 12)\n",
        "for i, uid in tqdm(enumerate(val_set['customer_id'])):\n",
        "    pred = [data['item']['article_id'].values[x] for x in I[i]]\n",
        "    predictions[uid] = pred\n",
        "\n",
        "uid = list(predictions.keys())\n",
        "product_list = [' '.join([str(i) for i in predictions[x]]) for x in uid]\n",
        "\n",
        "val_pred = pd.DataFrame(columns=['customer_id','prediction'])\n",
        "val_pred['customer_id'] = uid\n",
        "val_pred['prediction'] = product_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_label = pd.merge(val_label, val_pred, on='customer_id', how='left')"
      ],
      "metadata": {
        "id": "j6suOLX6ttzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use top12 articles to impute cold start users\n",
        "trans_week = data['trans'].loc[('2020-09-15' >= data['trans'].t_dat) & (data['trans'].t_dat >= '2020-09-09')]\n",
        "top12_products = data['trans'].article_id.value_counts().index[:12].tolist()\n",
        "top12_products = ' '.join([str(x) for x in top12_products])"
      ],
      "metadata": {
        "id": "TrG5F3EduqNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label['prediction'] = val_label['prediction'].fillna(top12_products)"
      ],
      "metadata": {
        "id": "aL-d9SDm05G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label['prediction'] = val_label['prediction'].apply(lambda x:[int(i) for i in x.split()])\n",
        "val_label['article_id'] = val_label['article_id'].apply(lambda x:[int(i) for i in x.split()])"
      ],
      "metadata": {
        "id": "svGVBvSK0OpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label.head()"
      ],
      "metadata": {
        "id": "DBWf2QhiB_Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapk(val_label['article_id'], val_label['prediction'], k=12)"
      ],
      "metadata": {
        "id": "54_auJAI5Dln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare with rule method"
      ],
      "metadata": {
        "id": "Jy_G9LD5LVi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = data['trans'].loc['2020-09-15' >= data['trans'].t_dat]\n",
        "train['t_dat'] = pd.to_datetime(train['t_dat'])\n",
        "\n",
        "tmp = train.groupby('customer_id').t_dat.max().reset_index()\n",
        "tmp.columns = ['customer_id','max_dat']\n",
        "train = train.merge(tmp,on=['customer_id'],how='left')\n",
        "train['diff_dat'] = (train.max_dat - train.t_dat).dt.days\n",
        "train = train.loc[train['diff_dat']<=6]\n",
        "print('Train shape:',train.shape)\n",
        "\n",
        "tmp = train.groupby(['customer_id','article_id'])['t_dat'].agg('count').reset_index()\n",
        "tmp.columns = ['customer_id','article_id','ct']\n",
        "train = train.merge(tmp,on=['customer_id','article_id'],how='left')\n",
        "train = train.sort_values(['ct','t_dat'],ascending=False)\n",
        "train = train.drop_duplicates(['customer_id','article_id'])\n",
        "train = train.sort_values(['ct','t_dat'],ascending=False)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "tihSXB6I5TpU",
        "outputId": "b7aa06c5-6c81-45ae-8555-601293df30f8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (5184732, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-998312b8-c81e-4805-8553-492cc92fbdf8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t_dat</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>article_id</th>\n",
              "      <th>price</th>\n",
              "      <th>sales_channel_id</th>\n",
              "      <th>max_dat</th>\n",
              "      <th>diff_dat</th>\n",
              "      <th>ct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1166592</th>\n",
              "      <td>2019-07-16</td>\n",
              "      <td>133198</td>\n",
              "      <td>58252</td>\n",
              "      <td>0.022017</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-07-16</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78195</th>\n",
              "      <td>2018-10-04</td>\n",
              "      <td>1292057</td>\n",
              "      <td>13264</td>\n",
              "      <td>0.016932</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-10-04</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2175362</th>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>109769</td>\n",
              "      <td>92111</td>\n",
              "      <td>0.033881</td>\n",
              "      <td>2</td>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>0</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3490510</th>\n",
              "      <td>2020-07-06</td>\n",
              "      <td>757724</td>\n",
              "      <td>46352</td>\n",
              "      <td>0.016932</td>\n",
              "      <td>2</td>\n",
              "      <td>2020-07-06</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876887</th>\n",
              "      <td>2019-05-14</td>\n",
              "      <td>152290</td>\n",
              "      <td>49881</td>\n",
              "      <td>0.033881</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-05-14</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-998312b8-c81e-4805-8553-492cc92fbdf8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-998312b8-c81e-4805-8553-492cc92fbdf8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-998312b8-c81e-4805-8553-492cc92fbdf8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             t_dat  customer_id  article_id  ...    max_dat  diff_dat   ct\n",
              "1166592 2019-07-16       133198       58252  ... 2019-07-16         0  100\n",
              "78195   2018-10-04      1292057       13264  ... 2018-10-04         0   86\n",
              "2175362 2020-03-06       109769       92111  ... 2020-03-06         0   81\n",
              "3490510 2020-07-06       757724       46352  ... 2020-07-06         0   80\n",
              "876887  2019-05-14       152290       49881  ... 2019-05-14         0   80\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vc = train.article_id.value_counts()\n",
        "# pairs = {}\n",
        "# for j,i in enumerate(vc.index.values[1000:1032]):\n",
        "#     #if j%10==0: print(j,', ',end='')\n",
        "#     USERS = train.loc[train.article_id==i.item(),'customer_id'].unique()\n",
        "#     vc2 = train.loc[(train.customer_id.isin(USERS))&(train.article_id!=i.item()),'article_id'].value_counts()\n",
        "#     pairs[i.item()] = [vc2.index[0], vc2.index[1], vc2.index[2]]\n",
        "pairs = np.load('/content/drive/MyDrive/HM-RecSys/data/pairs_cudf.npy',allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "dkUJX1o26cQi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['article_id2'] = train.article_id.map(pairs)"
      ],
      "metadata": {
        "id": "A02vB5o4637_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train2 = train[['customer_id','article_id2']].copy()\n",
        "train2 = train2.loc[train2.article_id2.notnull()]\n",
        "train2 = train2.drop_duplicates(['customer_id','article_id2'])\n",
        "train2 = train2.rename({'article_id2':'article_id'},axis=1)"
      ],
      "metadata": {
        "id": "4ZF4VT-k66cG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['customer_id','article_id']]\n",
        "train = pd.concat([train,train2],axis=0,ignore_index=True)\n",
        "train.article_id = train.article_id.astype('int32')\n",
        "train = train.drop_duplicates(['customer_id','article_id'])"
      ],
      "metadata": {
        "id": "WrWFUaNG7eNm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['article_id'] = ' '+train['article_id'].astype(str)"
      ],
      "metadata": {
        "id": "mXT9ka-H_FNE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = train.groupby('customer_id').article_id.sum().reset_index()\n",
        "pred.rename(columns={'article_id':'prediction2'},inplace=True)"
      ],
      "metadata": {
        "id": "vys4wa9n_JM-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label = pd.merge(val_label, pred, on=['customer_id'], how='left')"
      ],
      "metadata": {
        "id": "q8e6irpD_dEx"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_label['prediction2'] = val_label['prediction2'].fillna(top12_products)\n",
        "val_label['prediction2'] = val_label['prediction2'].apply(lambda x:[int(i) for i in x.split()])"
      ],
      "metadata": {
        "id": "HqfmhZ7E_sgJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapk(val_label['article_id'], val_label['prediction2'], k=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjIzbn01AHLJ",
        "outputId": "2bef435b-7a7b-4932-98a1-ed2d19494da9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019951609781481867"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit"
      ],
      "metadata": {
        "id": "F7H3wbpIuQab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = val_pred"
      ],
      "metadata": {
        "id": "aoPWN1dJUa-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP0lPp2Gfd-s"
      },
      "outputs": [],
      "source": [
        "map_path = dp.base + 'index_id_map/'\n",
        "\n",
        "user_index2id_dict = pickle.load(open(map_path+'/user_index2id.pkl','rb'))\n",
        "item_index2id_dict = pickle.load(open(map_path+'/item_index2id.pkl','rb'))\n",
        "\n",
        "pred_df['customer_id'] = pred_df['customer_id'].map(user_index2id_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXzM-C4OhKGV"
      },
      "outputs": [],
      "source": [
        "pred_df['prediction'] = pred_df['prediction'].apply(lambda x:' '.join([str(item_index2id_dict[s]) for s in x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcQ2snyldHXq"
      },
      "outputs": [],
      "source": [
        "trans_week = data['trans'].loc[data['trans'].t_dat >= '2020-09-09']\n",
        "top12_products = data['trans'].article_id.value_counts().index[:12].tolist()\n",
        "top12_products = [item_index2id_dict[i] for i in top12_products]\n",
        "top12_products = ' '.join([str(x) for x in top12_products])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B146l6uVeKM4"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/content/drive/MyDrive/HM-RecSys/data/sample_submission.csv')\n",
        "del sub['prediction']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_5rYxvbh8Mf"
      },
      "outputs": [],
      "source": [
        "sub = pd.merge(sub, pred_df, on=['customer_id'], how='left')\n",
        "sub['prediction'][sub['prediction'].isna()] = top12_products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmgw4Syaiq84"
      },
      "outputs": [],
      "source": [
        "sub[['customer_id','prediction']].to_csv('/content/drive/MyDrive/HM-RecSys/submit/baseline.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJNacJiCi0gF"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/HM-RecSys/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions submit -c h-and-m-personalized-fashion-recommendations -f /content/drive/MyDrive/HM-RecSys/submit/baseline.csv -m \"baseline\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVeecBGzi-li"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DeepMatch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}